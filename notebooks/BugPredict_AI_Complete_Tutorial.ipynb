{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ BugPredict AI - Complete Tutorial\n",
    "\n",
    "This notebook demonstrates the complete BugPredict AI workflow:\n",
    "\n",
    "1. **Data Collection** - Gather vulnerability data from HackerOne, Bugcrowd, and NVD\n",
    "2. **Data Preprocessing** - Clean and normalize data\n",
    "3. **Feature Engineering** - Extract 100+ features\n",
    "4. **Model Training** - Train ensemble models\n",
    "5. **Inference** - Predict vulnerabilities for new targets\n",
    "6. **Analysis** - Generate actionable reports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup\n",
    "\n",
    "First, let's import all necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# BugPredict AI imports\n",
    "from src.collectors.hackerone_scraper import HackerOneCollector\n",
    "from src.collectors.bugcrowd_scraper import BugcrowdCollector\n",
    "from src.collectors.cve_collector import CVECollector\n",
    "from src.preprocessing.normalizer import DataNormalizer\n",
    "from src.preprocessing.deduplicator import Deduplicator\n",
    "from src.preprocessing.enricher import DataEnricher\n",
    "from src.features.feature_engineer import FeatureEngineer\n",
    "from src.models.vulnerability_classifier import VulnerabilityPredictor\n",
    "from src.models.severity_predictor import SeverityPredictor\n",
    "from src.models.chain_detector import ChainDetector\n",
    "from src.inference.predictor import ThreatPredictor\n",
    "from src.training.pipeline import TrainingPipeline\n",
    "\n",
    "# Visualization settings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Part 1: Data Collection\n",
    "\n",
    "Let's collect vulnerability data from multiple sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 HackerOne Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Collecting data from HackerOne...\\n\")\n",
    "\n",
    "# Initialize collector\n",
    "h1_collector = HackerOneCollector()\n",
    "\n",
    "# Collect reports (uses cache if available)\n",
    "h1_reports = h1_collector.collect(limit=1000, use_cache=True)\n",
    "\n",
    "print(f\"\\n‚úì Collected {len(h1_reports)} reports from HackerOne\")\n",
    "\n",
    "# Show sample report\n",
    "if h1_reports:\n",
    "    sample = h1_reports[0]\n",
    "    print(f\"\\nSample Report:\")\n",
    "    print(f\"  ID: {sample.report_id}\")\n",
    "    print(f\"  Type: {sample.vulnerability_type}\")\n",
    "    print(f\"  Severity: {sample.severity}\")\n",
    "    print(f\"  Target: {sample.target_domain}\")\n",
    "    print(f\"  Bounty: ${sample.bounty_amount}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 CVE/NVD Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Collecting CVEs from NVD...\\n\")\n",
    "\n",
    "# Initialize collector\n",
    "cve_collector = CVECollector()\n",
    "\n",
    "# Date range: last 180 days\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=180)\n",
    "\n",
    "# Collect CVEs\n",
    "cve_reports = cve_collector.collect(\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    keywords=['web', 'application'],\n",
    "    limit=500,\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Collected {len(cve_reports)} CVEs\")\n",
    "\n",
    "# Show sample\n",
    "if cve_reports:\n",
    "    sample = cve_reports[0]\n",
    "    print(f\"\\nSample CVE:\")\n",
    "    print(f\"  ID: {sample.report_id}\")\n",
    "    print(f\"  Type: {sample.vulnerability_type}\")\n",
    "    print(f\"  CVSS: {sample.cvss_score}\")\n",
    "    print(f\"  Description: {sample.description[:100]}...\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Combine All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Combine all reports\n",
    "all_reports = h1_reports + cve_reports\n",
    "\n",
    "print(f\"Total reports collected: {len(all_reports)}\")\n",
    "\n",
    "# Data distribution\n",
    "platforms = pd.Series([r.platform for r in all_reports])\n",
    "print(f\"\\nData sources:\")\n",
    "print(platforms.value_counts())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Visualize Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Vulnerability type distribution\n",
    "vuln_types = pd.Series([r.vulnerability_type for r in all_reports])\n",
    "top_vulns = vuln_types.value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_vulns.plot(kind='barh', color='steelblue')\n",
    "plt.title('Top 10 Vulnerability Types', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Vulnerability Type')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Severity distribution\n",
    "severities = pd.Series([r.severity for r in all_reports])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "severities.value_counts().plot(kind='pie', autopct='%1.1f%%', colors=sns.color_palette('RdYlGn_r'))\n",
    "plt.title('Severity Distribution', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßπ Part 2: Data Preprocessing\n",
    "\n",
    "Clean and normalize the collected data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Normalizing data...\")\n",
    "\n",
    "normalizer = DataNormalizer()\n",
    "normalized_reports = normalizer.normalize(all_reports)\n",
    "\n",
    "print(f\"‚úì Normalized {len(normalized_reports)} reports\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Removing duplicates...\")\n",
    "\n",
    "deduplicator = Deduplicator()\n",
    "deduplicated_reports = deduplicator.deduplicate(normalized_reports)\n",
    "\n",
    "removed = len(normalized_reports) - len(deduplicated_reports)\n",
    "print(f\"‚úì Removed {removed} duplicates\")\n",
    "print(f\"‚úì {len(deduplicated_reports)} unique reports remaining\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Enrich Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Enriching data...\")\n",
    "\n",
    "enricher = DataEnricher()\n",
    "enriched_reports = enricher.enrich(deduplicated_reports)\n",
    "\n",
    "print(f\"‚úì Enriched {len(enriched_reports)} reports\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öôÔ∏è Part 3: Feature Engineering\n",
    "\n",
    "Extract 100+ features from vulnerability reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Engineering features...\\n\")\n",
    "\n",
    "feature_engineer = FeatureEngineer()\n",
    "features_df = feature_engineer.fit_transform(enriched_reports)\n",
    "\n",
    "print(f\"\\n‚úì Generated {features_df.shape[1]} features\")\n",
    "print(f\"‚úì Dataset shape: {features_df.shape}\")\n",
    "\n",
    "# Show sample features\n",
    "print(\"\\nSample features:\")\n",
    "print(features_df.head())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Numeric features summary\n",
    "numeric_features = features_df.select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_features.columns)}\")\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(numeric_features.describe())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Correlation heatmap (top features)\n",
    "top_features = numeric_features.columns[:20]\n",
    "corr_matrix = numeric_features[top_features].corr()\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix (Top 20)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Part 4: Model Training\n",
    "\n",
    "Train ensemble ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract targets\n",
    "y_vuln = features_df['vuln_type'].values\n",
    "y_severity = features_df['severity'].values\n",
    "y_cvss = features_df['cvss_score'].values\n",
    "\n",
    "# Extract features (only numeric)\n",
    "X = features_df.drop(['vuln_type', 'severity', 'cvss_score'], axis=1, errors='ignore')\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "X = X[numeric_cols]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target classes: {len(np.unique(y_vuln))}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, sev_train, sev_test, cvss_train, cvss_test = train_test_split(\n",
    "    X, y_vuln, y_severity, y_cvss,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_vuln\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train Vulnerability Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Training Vulnerability Classifier...\\n\")\n",
    "\n",
    "# Initialize and build\n",
    "vuln_predictor = VulnerabilityPredictor(random_state=42)\n",
    "vuln_predictor.build_models()\n",
    "\n",
    "# Train\n",
    "vuln_results = vuln_predictor.train(\n",
    "    pd.DataFrame(X_train, columns=X.columns),\n",
    "    pd.Series(y_train),\n",
    "    test_size=0.0,  # Already split\n",
    "    validation_size=0.1,\n",
    "    perform_cv=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Vulnerability Classifier trained!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Train Severity Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Training Severity Predictor...\\n\")\n",
    "\n",
    "# Initialize\n",
    "severity_predictor = SeverityPredictor(random_state=42)\n",
    "severity_predictor.build_model()\n",
    "\n",
    "# Train\n",
    "severity_results = severity_predictor.train(\n",
    "    pd.DataFrame(X_train, columns=X.columns),\n",
    "    pd.Series(sev_train),\n",
    "    y_cvss=pd.Series(cvss_train),\n",
    "    test_size=0.0,\n",
    "    perform_cv=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Severity Predictor trained!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate on test set\n",
    "eval_results = vuln_predictor.evaluate(\n",
    "    pd.DataFrame(X_test, columns=X.columns),\n",
    "    pd.Series(y_test),\n",
    "    method='averaging'\n",
    ")\n",
    "\n",
    "print(f\"Ensemble Test Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "print(f\"Ensemble Test F1 Score: {eval_results['f1_score']:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_pred, _ = vuln_predictor.ensemble_predict(\n",
    "    pd.DataFrame(X_test, columns=X.columns),\n",
    "    method='averaging'\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred,\n",
    "    ax=ax,\n",
    "    cmap='Blues',\n",
    "    colorbar=True\n",
    ")\n",
    "plt.title('Confusion Matrix - Vulnerability Classifier', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get feature importance\n",
    "importance_df = vuln_predictor.get_feature_importance(top_n=20, model_name='random_forest')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='steelblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Most Important Features', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(importance_df.head(10))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create models directory\n",
    "models_dir = Path('../data/models')\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "vuln_predictor.save(str(models_dir / 'vulnerability_predictor.pkl'))\n",
    "severity_predictor.save(str(models_dir / 'severity_predictor.pkl'))\n",
    "feature_engineer.save(str(models_dir / 'feature_engineer.pkl'))\n",
    "\n",
    "# Save chain detector\n",
    "chain_detector = ChainDetector()\n",
    "import pickle\n",
    "with open(models_dir / 'chain_detector.pkl', 'wb') as f:\n",
    "    pickle.dump(chain_detector, f)\n",
    "\n",
    "print(\"‚úì All models saved!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Part 5: Inference & Prediction\n",
    "\n",
    "Use trained models to predict vulnerabilities for new targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Load Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Loading trained models...\\n\")\n",
    "\n",
    "predictor = ThreatPredictor(models_dir='../data/models')\n",
    "\n",
    "print(\"\\n‚úì Models loaded and ready!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Analyze a Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define target\n",
    "target_info = {\n",
    "    'domain': 'example.com',\n",
    "    'company_name': 'Example Corp',\n",
    "    'technology_stack': ['React', 'Node.js', 'PostgreSQL', 'Redis', 'AWS'],\n",
    "    'endpoints': ['/api/users', '/api/posts', '/api/auth/login', '/api/payments'],\n",
    "    'auth_required': True,\n",
    "    'has_api': True,\n",
    "    'description': 'Social media platform with payment integration'\n",
    "}\n",
    "\n",
    "# Analyze\n",
    "results = predictor.analyze_target(target_info)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ANALYSIS COMPLETE\")\n",
    "print(f\"{'='*70}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Risk score\n",
    "print(f\"\\nRisk Score: {results['risk_score']}/10 ({results['risk_level'].upper()})\")\n",
    "\n",
    "# Top vulnerabilities\n",
    "print(f\"\\nTop 10 Vulnerability Predictions:\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "vuln_df = pd.DataFrame(results['vulnerability_predictions'][:10])\n",
    "print(vuln_df.to_string(index=False))\n",
    "\n",
    "# Chains\n",
    "if results['chain_predictions']:\n",
    "    print(f\"\\nDetected Attack Chains:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for chain in results['chain_predictions'][:3]:\n",
    "        print(f\"\\n{chain['name']} (Score: {chain['exploitability_score']}/10)\")\n",
    "        print(f\"  Vulnerabilities: {', '.join(chain['vulns'])}\")\n",
    "        print(f\"  Description: {chain['description']}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Vulnerability probability chart\n",
    "top_vulns = results['vulnerability_predictions'][:10]\n",
    "vuln_names = [v['vulnerability_type'] for v in top_vulns]\n",
    "vuln_probs = [v['probability'] for v in top_vulns]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.barh(vuln_names, vuln_probs, color='steelblue')\n",
    "\n",
    "# Color code by probability\n",
    "for i, (bar, prob) in enumerate(zip(bars, vuln_probs)):\n",
    "    if prob > 0.7:\n",
    "        bar.set_color('red')\n",
    "    elif prob > 0.5:\n",
    "        bar.set_color('orange')\n",
    "    else:\n",
    "        bar.set_color('steelblue')\n",
    "\n",
    "plt.xlabel('Probability', fontsize=12)\n",
    "plt.title('Vulnerability Predictions for example.com', fontsize=14, fontweight='bold')\n",
    "plt.xlim(0, 1)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Add probability labels\n",
    "for i, prob in enumerate(vuln_probs):\n",
    "    plt.text(prob + 0.02, i, f'{prob:.1%}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Test Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display test strategy\n",
    "strategy = results['test_strategy']\n",
    "\n",
    "print(f\"\\nRecommended Test Strategy\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for target in strategy['priority_targets'][:5]:\n",
    "    print(f\"\\n{target['vulnerability']} ({target['time_allocation']})\")\n",
    "    print(f\"  Priority: {'‚≠ê' * target['priority']}\")\n",
    "    print(f\"  Tools: {', '.join(target['tools'][:3])}\")\n",
    "    print(f\"  Test Cases:\")\n",
    "    for i, test_case in enumerate(target['test_cases'][:3], 1):\n",
    "        print(f\"    {i}. {test_case}\")\n",
    "\n",
    "# Time allocation pie chart\n",
    "if strategy['time_allocation']:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    labels = list(strategy['time_allocation'].keys())[:5]\n",
    "    sizes = list(strategy['time_allocation'].values())[:5]\n",
    "    \n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Recommended Time Allocation', fontsize=14, fontweight='bold')\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(f\"\\nActionable Recommendations\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for i, rec in enumerate(results['recommendations'], 1):\n",
    "    print(f\"{i}. {rec}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì¶ Part 6: Batch Analysis\n",
    "\n",
    "Analyze multiple targets at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define multiple targets\n",
    "targets = [\n",
    "    {\n",
    "        'domain': 'site1.com',\n",
    "        'company_name': 'Site 1',\n",
    "        'technology_stack': ['React', 'Node.js'],\n",
    "        'auth_required': True,\n",
    "        'has_api': True\n",
    "    },\n",
    "    {\n",
    "        'domain': 'site2.com',\n",
    "        'company_name': 'Site 2',\n",
    "        'technology_stack': ['Angular', 'Java', 'MySQL'],\n",
    "        'auth_required': True,\n",
    "        'has_api': True\n",
    "    },\n",
    "    {\n",
    "        'domain': 'site3.com',\n",
    "        'company_name': 'Site 3',\n",
    "        'technology_stack': ['Vue.js', 'Python', 'PostgreSQL'],\n",
    "        'auth_required': False,\n",
    "        'has_api': True\n",
    "    }\n",
    "]\n",
    "\n",
    "# Batch analyze\n",
    "print(\"Analyzing multiple targets...\\n\")\n",
    "batch_results = predictor.batch_analyze(targets)\n",
    "\n",
    "print(f\"\\n‚úì Analyzed {len(batch_results)} targets\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare risk scores\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'Target': r['target'],\n",
    "        'Risk Score': r['risk_score'],\n",
    "        'Risk Level': r['risk_level'],\n",
    "        'Top Vulnerability': r['vulnerability_predictions'][0]['vulnerability_type'],\n",
    "        'Top Probability': f\"{r['vulnerability_predictions'][0]['probability']:.1%}\",\n",
    "        'Chains': len(r['chain_predictions'])\n",
    "    }\n",
    "    for r in batch_results if 'error' not in r\n",
    "])\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Risk score comparison chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['red' if level == 'critical' else 'orange' if level == 'high' else 'yellow' if level == 'medium' else 'green' \n",
    "          for level in comparison_df['Risk Level']]\n",
    "\n",
    "plt.bar(comparison_df['Target'], comparison_df['Risk Score'], color=colors)\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Risk Score')\n",
    "plt.title('Risk Score Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylim(0, 10)\n",
    "plt.axhline(y=6, color='orange', linestyle='--', alpha=0.5, label='High Risk Threshold')\n",
    "plt.axhline(y=8, color='red', linestyle='--', alpha=0.5, label='Critical Risk Threshold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Part 7: Export Results\n",
    "\n",
    "Save results for reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "# Save individual analysis\n",
    "output_dir = Path('../data/results')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(output_dir / 'example_analysis.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"‚úì Saved to data/results/example_analysis.json\")\n",
    "\n",
    "# Save batch results\n",
    "with open(output_dir / 'batch_analysis.json', 'w') as f:\n",
    "    json.dump(batch_results, f, indent=2)\n",
    "\n",
    "print(\"‚úì Saved to data/results/batch_analysis.json\")\n",
    "\n",
    "# Save comparison CSV\n",
    "comparison_df.to_csv(output_dir / 'comparison.csv', index=False)\n",
    "\n",
    "print(\"‚úì Saved to data/results/comparison.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. ‚úÖ **Collected** vulnerability data from HackerOne and NVD\n",
    "2. ‚úÖ **Preprocessed** data (normalization, deduplication, enrichment)\n",
    "3. ‚úÖ **Engineered** 100+ features from reports\n",
    "4. ‚úÖ **Trained** ensemble ML models (Random Forest, XGBoost, LightGBM, etc.)\n",
    "5. ‚úÖ **Evaluated** model performance (accuracy, F1 score, confusion matrix)\n",
    "6. ‚úÖ **Predicted** vulnerabilities for new targets\n",
    "7. ‚úÖ **Generated** actionable test strategies\n",
    "8. ‚úÖ **Detected** attack chains\n",
    "9. ‚úÖ **Analyzed** multiple targets in batch\n",
    "10. ‚úÖ **Exported** results for reporting\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Use `scripts/analyze_target.py` for CLI analysis\n",
    "- Use `scripts/batch_analyze.py` for batch processing\n",
    "- Use `scripts/generate_nuclei_templates.py` to create Nuclei templates\n",
    "- Integrate with your bug bounty workflow\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [Documentation](../docs/)\n",
    "- [GitHub Repository](https://github.com/yourusername/bugpredict-ai)\n",
    "- [API Documentation](../docs/api.md)\n",
    "\n",
    "Happy Hunting! üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
